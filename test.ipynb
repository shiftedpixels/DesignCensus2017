{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://designcensus.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('DesignCensus2017_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There a a total of ' + str(len(df.columns)) + ' columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I, Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column name dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "for col in df.columns:\n",
    "    index, desc = col.split(' --')\n",
    "    col_dict['V_' + str(index)] = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_with_column_names(df, col_dict):\n",
    "    df_v2 = df\n",
    "    df_v2.columns = [col_dict[col] for col in df_v2.columns]\n",
    "    return df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify columns (continuous, categorical, multiple pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = map(lambda x : 'V_' + str(x+1), list(range(len(df.columns)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continous_cols = ['V_18', 'V_37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_col = ['V_2', 'V_3','V_5','V_7','V_11','V_19',\\\n",
    "            'V_24', 'V_27', 'V_28', 'V_31', 'V_32',\\\n",
    "            'V_33', 'V_40', 'V_41', 'V_42', 'V_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_cols = list(set(df.columns) - set(continous_cols))\n",
    "cate_cols.sort(key = lambda x : int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of null value for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(columns=['Column','Desc', 'Null'])\n",
    "for col in df.columns:\n",
    "    num_null = df[col].isnull().sum()\n",
    "    dff = dff.append({'Column': col, 'Desc' : col_dict[col], 'Null' : num_null }, ignore_index=True)\n",
    "dff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Take a look at Salary Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The 99% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 99))))\n",
    "\n",
    "print('The 90% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 90))))\n",
    "\n",
    "print('The 85% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 85))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at salary vs. age\n",
    "dff = pd.DataFrame()\n",
    "dff['salary'] = df['V_18'] / 1000\n",
    "dff['age'] = df['V_37']\n",
    "dff['salary over million'] = dff['salary'] > 1000\n",
    "sns.lmplot(data = dff, x = 'salary', y = 'age', fit_reg = False, hue = 'salary over million')\n",
    "plt.xlabel('Salary (thousand)')\n",
    "plt.ylabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export a separate file with salary over million record\n",
    "# df_with_column_names(df[df.V_18 > 1000000], col_dict).to_csv('output_salary_over_million.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Break \"Age\" into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_break(x):\n",
    "    if (x < 20): return ('Younger than 20')\n",
    "    elif (x <= 25): return ('20 to 25')\n",
    "    elif (x <= 30): return ('25 to 30')\n",
    "    elif (x <= 35): return ('30 to 35')\n",
    "    elif (x <= 40): return ('35 to 40')\n",
    "    elif (x <= 45): return ('40 to 45')\n",
    "    elif (x <= 50): return ('45 to 50')\n",
    "    else: return ('Older than 50')\n",
    "\n",
    "df['V_37'] = df['V_37'].apply(lambda x : age_break(x))\n",
    "cate_cols.append('V_37')\n",
    "continous_cols.remove('V_37')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exclude outliers for salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove outliers for salary\n",
    "# 1. Null values \n",
    "# 2. zero salary\n",
    "# 3. Top 1% salary\n",
    "\n",
    "df = df[~((df.V_18.isnull()) | \n",
    "          (df.V_18 == 0) | \n",
    "          (df.V_18 > 210000))]\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Done for Jon to export raw data with and without salary outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('DesignCensus2017_Data.csv')\n",
    "salary = raw_df['18 --My annual salary is:']\n",
    "raw_df_salary_outliers  = raw_df [((salary.isnull()) | (salary == 0) | (salary > 210000))]\n",
    "raw_df_excluding_outliers  = raw_df [~((salary.isnull()) | (salary == 0) | (salary > 210000))]\n",
    "raw_df_salary_outliers.to_csv('./export_csv/raw_data_salary_outliers.csv', index = False)\n",
    "raw_df_excluding_outliers.to_csv('./export_csv/raw_data_excluding_salary_outliers.csv', index = False)\n",
    "del raw_df, raw_df_salary_outliers, raw_df_excluding_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to deal with columns with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['V_36'] = df['V_36'].astype(np.object)\n",
    "df = df.replace(np.nan,'', regex=True)\n",
    "pipe_col_dict = {}\n",
    "\n",
    "for col in pipe_col:\n",
    "    options = set()\n",
    "    for row in df[col]:\n",
    "        arrs = row.split('|') \n",
    "        for arr in arrs:\n",
    "            if arr != '':\n",
    "                options.add(arr)\n",
    "    \n",
    "    pipe_col_dict[col] = {}\n",
    "    \n",
    "    index = 1\n",
    "    for option in options:\n",
    "        sub_col = col + '_' + str(index)\n",
    "        df.loc[:,sub_col] = 0\n",
    "        pipe_col_dict[col][option] = sub_col\n",
    "        col_dict[sub_col] = col_dict[col] + '-' + option\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this part takes a few minutes to run\n",
    "for col in pipe_col:\n",
    "    row_num = 0;\n",
    "    for row in df[col]:\n",
    "        arrs = row.split('|') \n",
    "        for arr in arrs:\n",
    "            if arr != '':\n",
    "                sub_col = pipe_col_dict[col][arr]\n",
    "                df.loc[row_num, sub_col] += 1\n",
    "        row_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output csv w/ and w/o column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./export_csv/processed_output_without_column_names.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_column_names(df, col_dict).to_csv(\\\n",
    "    './export_csv/processed_output_with_column_names.csv', index = False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II, Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./export_csv/processed_output_without_column_names.csv')\n",
    "num_records = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Summary of each column (only show top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_cate_col(col, top_k):\n",
    "    if col in continous_cols:\n",
    "        return\n",
    "    \n",
    "    elif col in pipe_col:\n",
    "        dff = pd.DataFrame(columns=['Options','Count','Percent'])\n",
    "        for key, value in pipe_col_dict[col].items():\n",
    "            count = df[value].sum()\n",
    "            dff = dff.append({'Options': key, 'Count' : count}, ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        dff = pd.DataFrame(df[col].value_counts())\n",
    "        dff.reset_index(inplace=True)\n",
    "        dff.columns = ['Options','Count']\n",
    "    \n",
    "    dff['Percent'] = dff.Count / num_records\n",
    "    dff = dff.sort_values(by = 'Percent', ascending = False).head(top_k)\n",
    "    dff = dff.style.format({'Percent': '{:,.2%}'.format})\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change `top_k` below: summary_cate_col(col, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cate_cols:\n",
    "    display(str(col) + ' : ' + col_dict[col])\n",
    "    display(summary_cate_col(col, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Further explore salary by plotting `salary` vs. all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. For columns without pipes\n",
    "cate_cols_v2 = list(set(cate_cols) - set(pipe_col))\n",
    "cate_cols_v2.remove('V_35') # \"Right now, I can't stop listening to:\" - No fixed options\n",
    "cate_cols_v2.remove('V_36') # \"I live in:\" - Zipcode\n",
    "cate_cols_v2.remove('V_8') # \"I'm not working because:\" - null\n",
    "cate_cols_v2.sort(key = lambda x : int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All figs are saved under 'fig' folder\n",
    "for col in cate_cols_v2:\n",
    "    groupedvalues = df.groupby(col, as_index = False).agg({'V_18': np.mean}).sort_values(by = 'V_18')\n",
    "    order = list(groupedvalues[col])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    g=sns.barplot(x='V_18', y=col, data=df, estimator= np.mean, \\\n",
    "                order = order,  palette=\"Blues_d\")\n",
    "    plt.xlim(0,max(groupedvalues['V_18'] + 10000))  \n",
    "    \n",
    "    # add data labels\n",
    "    ax = plt.gca()\n",
    "    for p,val in zip(ax.patches,groupedvalues['V_18']):\n",
    "        ax.annotate(\"{0:n}\".format(int(val)), # value\n",
    "                    (p.get_x() + p.get_width(),p.get_y()+0.5*p.get_height()),# location\n",
    "                    xytext=(5, 5), textcoords='offset points',# offset\n",
    "                    va=\"center\", size = 12) #text align and font size\n",
    "        \n",
    "    #plot axes and export\n",
    "    plt.ylabel('Salary')\n",
    "    plt.xlabel(col_dict[col])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./fig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.png',dpi=100)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. For columns with pipes\n",
    "dff = pd.DataFrame(columns = ['Col', 'Option', 'Salary'])\n",
    "for col in pipe_col:\n",
    "    for option, sub_col in pipe_col_dict[col].items():\n",
    "        salary = df.loc[df[sub_col] == 1, 'V_18'].mean()\n",
    "        dff = dff.append({'Col': col, 'Option' : option, 'Salary' : salary }, \\\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All figs are saved under 'fig' folder\n",
    "for col in pipe_col:\n",
    "    dfff = dff[dff.Col == col].sort_values(by = 'Salary')\n",
    "    order = list(dfff['Option'])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.barplot(x = 'Salary', y = 'Option', data = dfff, estimator= np.mean, \\\n",
    "                order = order, orient = 'H', palette=\"Blues_d\")\n",
    "    plt.xlim(0, max(dfff['Salary']) + 10000) \n",
    "    \n",
    "    # add data labels\n",
    "    ax = plt.gca()\n",
    "    for p,val in zip(ax.patches,dfff['Salary']):\n",
    "        ax.annotate(\"{0:n}\".format(int(val)), #value\n",
    "                    (p.get_x() + p.get_width(),p.get_y()+0.5*p.get_height()),# location\n",
    "                    xytext=(5, 0), textcoords='offset points',# offset\n",
    "                    va=\"center\", size = 12) # text align and font size\n",
    "     \n",
    "    #plot axes and export    \n",
    "    plt.ylabel('Salary')\n",
    "    plt.xlabel(col_dict[col])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./fig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.png',dpi=100)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
